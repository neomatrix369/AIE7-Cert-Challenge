{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18968a27-a5c1-4064-992d-21a7d4716ca5",
   "metadata": {
    "id": "e-IqJAMkwnCF"
   },
   "source": [
    "# [RAGAS] Advanced Retrieval with LangChain\n",
    "\n",
    "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
    "\n",
    "We'll touch on:\n",
    "\n",
    "- Naive Retrieval\n",
    "- Best-Matching 25 (BM25)\n",
    "- Multi-Query Retrieval\n",
    "- Parent-Document Retrieval\n",
    "- Contextual Compression (a.k.a. Rerank)\n",
    "- Ensemble Retrieval\n",
    "- Semantic chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c2a8e1-562b-42d3-9f00-932bce898211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_cohere'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore_functions\u001b[39;00m\n\u001b[32m      5\u001b[39m importlib.reload(core_utils)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_and_prepare_data, get_vector_store, get_naive_retriever, get_rag_prompt, get_chat_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/ai-ml-dl-stuff/ai_makerspace/AIE7-Cert-Challenge/core_functions.py:33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutput_parsers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI, OpenAIEmbeddings\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_cohere\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CohereRerank\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_qdrant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QdrantVectorStore\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqdrant_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QdrantClient, models\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_cohere'"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import core_functions\n",
    "\n",
    "importlib.reload(core_utils)\n",
    "\n",
    "from core_functions import load_and_prepare_data, get_vector_store, get_naive_retriever, get_rag_prompt, get_chat_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48651960-7802-41e3-9c95-48e00508e264",
   "metadata": {
    "id": "mw304iAFyRtl"
   },
   "source": [
    "## Task 2: Data Collection and Preparation\n",
    "\n",
    "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fc383-3cb4-4200-bf6b-eb5c51ff9ee4",
   "metadata": {
    "id": "A92NC2QZzCsi"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899108ab-5e15-4b18-ba65-431301da9eff",
   "metadata": {
    "id": "9gQphb6y0C0S"
   },
   "source": [
    "Let's look at an example document to see if everything worked as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5c5f1-ccf6-4cab-964a-98c4ac54fe48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5784-07e3-43f9-953b-dab024b0589c",
   "metadata": {
    "id": "lWaQpdHl0Gzc"
   },
   "source": [
    "## Task 3: Setting up QDrant!\n",
    "\n",
    "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
    "\n",
    "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
    "\n",
    "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd15f794-08d2-461f-a558-36bc398e9993",
   "metadata": {
    "id": "NT8ihRJbYmMT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorstore = get_vector_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c84ce-7259-4ad5-974d-8de80b7bb288",
   "metadata": {
    "id": "-x2SS4Rh0hiN"
   },
   "source": [
    "## Task 4: Naive RAG Chain\n",
    "\n",
    "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973f3ef-8044-4ec3-b104-db9691eac1e8",
   "metadata": {
    "id": "NEH7X5Ai08FH"
   },
   "source": [
    "### R - Retrieval\n",
    "\n",
    "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
    "\n",
    "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c749d4c-ec1b-4531-a203-d82a2b9d826f",
   "metadata": {
    "id": "GFDPrNBtb72o"
   },
   "outputs": [],
   "source": [
    "naive_retriever = get_naive_retriever(vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b403d-a564-4327-beb1-e59360a62539",
   "metadata": {
    "id": "MbBhyQjz06dx"
   },
   "source": [
    "### A - Augmented\n",
    "\n",
    "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c3baab-6f59-44bb-ae48-dc2765386f55",
   "metadata": {
    "id": "7uSz-Dbqcoki"
   },
   "outputs": [],
   "source": [
    "rag_prompt = get_rag_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1c722-71cc-4155-80ec-2c42edf6e6c2",
   "metadata": {
    "id": "BlRzpb231GGJ"
   },
   "source": [
    "### G - Generation\n",
    "\n",
    "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40df587a-ce1a-4a2b-b48a-e3a2ec20df1b",
   "metadata": {
    "id": "c-1t9H60dJLg"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = get_chat_model(\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0f4f4-25ff-4539-9a38-a9fcf3378078",
   "metadata": {
    "id": "mg3QRGzA1M2x"
   },
   "source": [
    "### LCEL RAG Chain\n",
    "\n",
    "We're going to use LCEL to construct our chain.\n",
    "\n",
    "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b44214-0f33-4ce0-acbf-b2dcf626f365",
   "metadata": {
    "id": "0bvstS7mdOW3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 ms, sys: 3.48 ms, total: 23.9 ms\n",
      "Wall time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "naive_retrieval_chain = get_naive_retrieval_chain(naive_retriever, rag_prompt, chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1aff428-a253-49fd-85e3-e82129b51412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38067067-2428-4616-8743-dac0374c08e6",
   "metadata": {
    "id": "Ft1vt8HPR16w"
   },
   "source": [
    "## Task 5: Best-Matching 25 (BM25) Retriever\n",
    "\n",
    "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
    "\n",
    "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
    "\n",
    "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402ca355-c8d8-4fff-9a37-13d2e7add0ed",
   "metadata": {
    "id": "qdF4wuj5R-cG"
   },
   "outputs": [],
   "source": [
    "bm25_retriever = get_bm25_retriever(filtered_loan_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17cbcf-6e1d-40ab-b24e-247eb984036a",
   "metadata": {
    "id": "KIjJlBQ8drKH"
   },
   "source": [
    "We'll construct the same chain - only changing the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8bcee38-569b-4610-bc79-99f7800ee4fe",
   "metadata": {
    "id": "WR15EQG7SLuw"
   },
   "outputs": [],
   "source": [
    "bm25_retrieval_chain = get_bm25_retriever_chain(bm25_retriever, rag_prompt, chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ae852ba-ab5e-4b20-aa51-c810d218fa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda75ca5-8cdf-485f-b54b-815f1c47c12c",
   "metadata": {
    "id": "Q-dcbFn2vpZF"
   },
   "source": [
    "## Task 6: Contextual Compression (Using Reranking)\n",
    "\n",
    "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
    "\n",
    "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
    "\n",
    "The basic idea here is this:\n",
    "\n",
    "- We retrieve lots of documents that are very likely related to our query vector\n",
    "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
    "\n",
    "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
    "\n",
    "All we need to do is the following:\n",
    "\n",
    "- Create a basic retriever\n",
    "- Create a compressor (reranker, in this case)\n",
    "\n",
    "That's it!\n",
    "\n",
    "Let's see it in the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "242d1015-8c4e-4b88-85da-51986770132b",
   "metadata": {
    "id": "psHvO2K1v_ZQ"
   },
   "outputs": [],
   "source": [
    "contextual_compression_retriever = get_contextual_compression_retriever(naive_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08fc9a-bda2-48b1-9d2a-9108909d2470",
   "metadata": {
    "id": "_TA9RB2x-j7P"
   },
   "source": [
    "Let's create our chain again, and see how this does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "157b291a-72d8-462f-b801-c9ca4184b7af",
   "metadata": {
    "id": "1BXqmxvHwX6T"
   },
   "outputs": [],
   "source": [
    "contextual_compression_retrieval_chain = get_compression_retriever_chain(\n",
    "    contextual_compression_retriever, rag_prompt, chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ea060-a6ff-4825-9c9b-46d2776e7c91",
   "metadata": {
    "id": "OEbT0g2S-mZ4"
   },
   "source": [
    "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a638ade-0c70-4760-a890-e801be7d1c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84c5965-1586-4368-b767-d0b6936dab14",
   "metadata": {
    "id": "qqbghrBEQNn5"
   },
   "source": [
    "## Task 7: Multi-Query Retriever\n",
    "\n",
    "Typically in RAG we have a single query - the one provided by the user.\n",
    "\n",
    "What if we had....more than one query!\n",
    "\n",
    "In essence, a Multi-Query Retriever works by:\n",
    "\n",
    "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
    "2. Retrieving documents for each query.\n",
    "3. Using all unique retrieved documents as context\n",
    "\n",
    "So, how is it to set-up? Not bad! Let's see it down below!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a3133ac-8d18-4b6a-a514-48ba3e58b811",
   "metadata": {
    "id": "pfM26ReXQjzU"
   },
   "outputs": [],
   "source": [
    "multi_query_retriever = get_multi_query_retriever(naive_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1afb9197-95f6-4d3f-abb6-97b6b01d4a6e",
   "metadata": {
    "id": "1vRc129jQ5WW"
   },
   "outputs": [],
   "source": [
    "multi_query_retrieval_chain = get_multi_query_retrieval_chain(multi_query_retriever, rag_prompt, chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce117649-9156-48b9-b260-070c44a1d4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ec295-fb12-430e-a7f0-47940cded114",
   "metadata": {
    "id": "EDEawBf_d_3G"
   },
   "source": [
    "## Task 8: Parent Document Retriever\n",
    "\n",
    "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
    "\n",
    "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
    "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
    "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
    "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
    "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
    "\n",
    "Okay, maybe that was a few steps - but the basic idea is this:\n",
    "\n",
    "- Search for small documents\n",
    "- Return big documents\n",
    "\n",
    "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
    "\n",
    "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db36743a-3a4b-45ea-adbd-b40c86418990",
   "metadata": {
    "id": "qJ53JJuMd_ZH"
   },
   "outputs": [],
   "source": [
    "parent_document_retrieval_chain = get_parent_document_retrieval_chain(parent_document_retriever, rag_prompt, chat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b3d9c-71d0-440c-898e-83d6e8979763",
   "metadata": {
    "id": "bI7Tip1335rE"
   },
   "source": [
    "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b959050-2b82-4e7b-8886-0b8374dded55",
   "metadata": {
    "id": "jNolUVQb4Apt"
   },
   "source": [
    "Let's give it a whirl!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d064963-9649-4f56-b7a8-7d5fc3d015d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ee22d-2782-4d57-afd3-edff901249ed",
   "metadata": {
    "id": "VUrIBKl_TwS9"
   },
   "source": [
    "## Task 9: Ensemble Retriever\n",
    "\n",
    "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
    "\n",
    "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
    "\n",
    "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5143a233-4b45-469f-8243-66df86bd5325",
   "metadata": {
    "id": "8j7jpZsKTxic"
   },
   "outputs": [],
   "source": [
    "ensemble_retriever = get_ensemble_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f8197-3337-4170-a017-110507a0a04e",
   "metadata": {
    "id": "kpo9Psl5hhJ-"
   },
   "source": [
    "We'll pack *all* of these retrievers together in an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e064c8b2-781c-481e-97d4-b6177c1c853b",
   "metadata": {
    "id": "KZ__EZwpUKkd"
   },
   "outputs": [],
   "source": [
    "ensemble_retrieval_chain = get_ensemble_retrieval_chain(\n",
    "    ensemble_retriever, rag_prompt, chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da88505-5311-4f28-80c2-2cc31c0d3018",
   "metadata": {
    "id": "SSsvHpRMj24L"
   },
   "source": [
    "Let's look at our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3df901a2-cf72-4d10-8fb0-4ca5804fd53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234787ce-3fe6-4b0e-8e82-e45b3201687e",
   "metadata": {
    "id": "MopbkNJAXVaN"
   },
   "source": [
    "## Task 10: Semantic Chunking\n",
    "\n",
    "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
    "\n",
    "Essentially, Semantic Chunking is implemented by:\n",
    "\n",
    "1. Embedding all sentences in the corpus.\n",
    "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
    "  - `percentile`\n",
    "  - `standard_deviation`\n",
    "  - `interquartile`\n",
    "  - `gradient`\n",
    "3. Each sequence of related sentences is kept as a document!\n",
    "\n",
    "Let's see how to implement this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28ca13-a683-4fe1-a2df-cee737825c3c",
   "metadata": {},
   "source": [
    "The `breakpoint_threshold_type` parameter controls when the semantic chunker creates chunk boundaries based on embedding similarity between sentences:\n",
    "\n",
    "**Four Threshold Types:**\n",
    "\n",
    "1. _\"percentile\" (default)_\n",
    "- Splits when sentence embedding distance exceeds the 95th percentile of all distances\n",
    "- Effect: Creates chunks at the most semantically distinct boundaries\n",
    "- Behavior: More conservative splitting, larger chunks\n",
    "\n",
    "2. _\"standard_deviation\"_\n",
    "- Splits when distance exceeds 3 standard deviations from mean\n",
    "- Effect: Better predictable performance, especially for normally distributed content\n",
    "- Behavior: More consistent chunk sizes\n",
    "\n",
    "3. _\"interquartile\"_\n",
    "- Uses IQR * 1.5 scaling factor to determine breakpoints\n",
    "- Effect: Middle-ground approach, robust to outliers\n",
    "- Behavior: Balanced chunk distribution\n",
    "\n",
    "4. _\"gradient\"_\n",
    "- Detects anomalies in embedding distance gradients\n",
    "- Effect: Best for domain-specific/highly correlated content\n",
    "- Behavior: Finds subtle semantic transitions\n",
    "\n",
    "**Impact:** _The threshold type determines sensitivity to semantic changes - more sensitive types create smaller, more focused chunks while less sensitive types create larger, more comprehensive chunks._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc2ae4a-9ed7-4412-aae6-36c49692f0a1",
   "metadata": {
    "id": "U9ciZbFEldv_"
   },
   "source": [
    "We'll use the `percentile` thresholding method for this example which will:\n",
    "\n",
    "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acb9114a-5fec-4ddf-b005-4d4b2c95d746",
   "metadata": {
    "id": "66EIEWiEYl5y"
   },
   "outputs": [],
   "source": [
    "semantic_retriever = get_semantic_retriever(loan_complaint_data, vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56917a4f-ef2b-4b5a-ac1e-8390946f1bfe",
   "metadata": {
    "id": "xWE_0J0mZveG"
   },
   "outputs": [],
   "source": [
    "semantic_retrieval_chain = get_semantic_retrieval_chain(semantic_retriever, rag_prompt, chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "618a3530-578e-458d-96bc-cd4dce3d999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_master = generate_golden_master()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fde2ef8d-f150-4750-b615-dc4d9bf17685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_examples_on_langsmith()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34805e88-8834-4ac3-ba51-b17cbe80cb6d",
   "metadata": {},
   "source": [
    "## Ragas Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e865b4a-797d-42cd-acbe-4d390dc81033",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_evaluation_dataset_after_applying_retrieval_chains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942b2f2-6dd2-4f7b-85c0-095d40609efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pipeline_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e2965-3492-45c0-972f-70b134d4b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ragas_evaluations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e3b1d-6bf6-4469-accc-6d89e60a2be1",
   "metadata": {},
   "source": [
    "## Evaluation and Performance Analysis\n",
    "\n",
    "Now that we have evaluation data from LangSmith, let's analyze the performance of different retrievers across multiple dimensions: **Performance**, **Cost**, and **Latency**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c1cef838-749c-4f6f-8e56-8b072e0ee79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "05c81e41-4fcc-468a-a24c-2ad030f3895b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fb3a146be54f578fe7b6ac668703df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_stats_df = gather_and_save_raw_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5cb33480-3092-4913-947a-1b6b2784cefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retriever</th>\n",
       "      <th>Total_Runs</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Total_Input_Tokens</th>\n",
       "      <th>Total_Output_Tokens</th>\n",
       "      <th>Total_Latency_Sec</th>\n",
       "      <th>Avg_Cost_Per_Run</th>\n",
       "      <th>Avg_Input_Tokens_Per_Run</th>\n",
       "      <th>Avg_Output_Tokens_Per_Run</th>\n",
       "      <th>Avg_Latency_Sec</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>llm_context_precision_without_reference</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>non_llm_context_precision_with_reference</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity_relevant</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>faithful_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naive_retrieval_chain</td>\n",
       "      <td>10</td>\n",
       "      <td>0.243176</td>\n",
       "      <td>659319</td>\n",
       "      <td>240463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024318</td>\n",
       "      <td>65931.9</td>\n",
       "      <td>24046.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.794524</td>\n",
       "      <td>0.918197</td>\n",
       "      <td>0.777317</td>\n",
       "      <td>0.392897</td>\n",
       "      <td>0.320769</td>\n",
       "      <td>0.223647</td>\n",
       "      <td>0.808040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25_retrieval_chain</td>\n",
       "      <td>10</td>\n",
       "      <td>0.150856</td>\n",
       "      <td>392780</td>\n",
       "      <td>153232</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>39278.0</td>\n",
       "      <td>15323.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.913889</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.413889</td>\n",
       "      <td>0.434487</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.870687</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contextual_compression_retrieval_chain</td>\n",
       "      <td>10</td>\n",
       "      <td>0.111962</td>\n",
       "      <td>280371</td>\n",
       "      <td>116510</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>28037.1</td>\n",
       "      <td>11651.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.639524</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.449487</td>\n",
       "      <td>0.406235</td>\n",
       "      <td>0.782676</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multi_query_retrieval_chain</td>\n",
       "      <td>10</td>\n",
       "      <td>0.254773</td>\n",
       "      <td>805097</td>\n",
       "      <td>223347</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025477</td>\n",
       "      <td>80509.7</td>\n",
       "      <td>22334.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.844524</td>\n",
       "      <td>0.908392</td>\n",
       "      <td>0.850487</td>\n",
       "      <td>0.359511</td>\n",
       "      <td>0.424487</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.896755</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parent_document_retrieval_chain</td>\n",
       "      <td>10</td>\n",
       "      <td>0.145341</td>\n",
       "      <td>365018</td>\n",
       "      <td>150980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>36501.8</td>\n",
       "      <td>15098.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.806190</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.445128</td>\n",
       "      <td>0.317317</td>\n",
       "      <td>0.883523</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensemble_retrieval_chain</td>\n",
       "      <td>10</td>\n",
       "      <td>0.283593</td>\n",
       "      <td>1023190</td>\n",
       "      <td>216857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028359</td>\n",
       "      <td>102319.0</td>\n",
       "      <td>21685.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.889890</td>\n",
       "      <td>0.767724</td>\n",
       "      <td>0.393110</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.891511</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                retriever  Total_Runs  Total_Cost  \\\n",
       "0                   naive_retrieval_chain          10    0.243176   \n",
       "0                    bm25_retrieval_chain          10    0.150856   \n",
       "0  contextual_compression_retrieval_chain          10    0.111962   \n",
       "0             multi_query_retrieval_chain          10    0.254773   \n",
       "0         parent_document_retrieval_chain          10    0.145341   \n",
       "0                ensemble_retrieval_chain          10    0.283593   \n",
       "\n",
       "   Total_Input_Tokens  Total_Output_Tokens  Total_Latency_Sec  \\\n",
       "0              659319               240463                  0   \n",
       "0              392780               153232                  0   \n",
       "0              280371               116510                  0   \n",
       "0              805097               223347                  0   \n",
       "0              365018               150980                  0   \n",
       "0             1023190               216857                  0   \n",
       "\n",
       "   Avg_Cost_Per_Run  Avg_Input_Tokens_Per_Run  Avg_Output_Tokens_Per_Run  \\\n",
       "0          0.024318                   65931.9                    24046.3   \n",
       "0          0.015086                   39278.0                    15323.2   \n",
       "0          0.011196                   28037.1                    11651.0   \n",
       "0          0.025477                   80509.7                    22334.7   \n",
       "0          0.014534                   36501.8                    15098.0   \n",
       "0          0.028359                  102319.0                    21685.7   \n",
       "\n",
       "   Avg_Latency_Sec  context_recall  llm_context_precision_without_reference  \\\n",
       "0                0        0.794524                                 0.918197   \n",
       "0                0        0.822857                                 0.913889   \n",
       "0                0        0.639524                                 0.983333   \n",
       "0                0        0.844524                                 0.908392   \n",
       "0                0        0.806190                                 0.933333   \n",
       "0                0        0.851429                                 0.889890   \n",
       "\n",
       "   llm_context_precision_with_reference  \\\n",
       "0                              0.777317   \n",
       "0                              0.683333   \n",
       "0                              0.733333   \n",
       "0                              0.850487   \n",
       "0                              0.858333   \n",
       "0                              0.767724   \n",
       "\n",
       "   non_llm_context_precision_with_reference  context_entity_recall  \\\n",
       "0                                  0.392897               0.320769   \n",
       "0                                  0.413889               0.434487   \n",
       "0                                  0.508333               0.449487   \n",
       "0                                  0.359511               0.424487   \n",
       "0                                  0.255556               0.445128   \n",
       "0                                  0.393110               0.474359   \n",
       "\n",
       "   noise_sensitivity_relevant  faithfulness  faithful_rate  \n",
       "0                    0.223647      0.808040            1.0  \n",
       "0                    0.379310      0.870687            1.0  \n",
       "0                    0.406235      0.782676            1.0  \n",
       "0                    0.454545      0.896755            1.0  \n",
       "0                    0.317317      0.883523            1.0  \n",
       "0                    0.000000      0.891511            1.0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "69d38a66-85b5-4b40-afc6-be3e450cda94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import ragas_rank_retrievers\n",
    "importlib.reload(ragas_rank_retrievers)\n",
    "from ragas_rank_retrievers import RetrieverRanker\n",
    "\n",
    "ranker = RetrieverRanker('ragas_retriever_raw_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56049e0d-e22e-47b6-b6c9-8bb446fc3336",
   "metadata": {},
   "source": [
    "## Final outcome of the Ragas Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7564b886-ffa5-4c8e-a43d-40c2957a836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranker.print_available_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "079a92f6-3232-4b91-b748-85d85cba021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Retriever</th>\n",
       "      <th>Key Metric</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall Winner</td>\n",
       "      <td>Parent Document</td>\n",
       "      <td>Score: 0.729</td>\n",
       "      <td>Best balanced performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budget Option</td>\n",
       "      <td>Contextual Compression</td>\n",
       "      <td>Cost: $0.0112</td>\n",
       "      <td>Lowest cost per run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quality Leader</td>\n",
       "      <td>Multi Query</td>\n",
       "      <td>Quality: 0.864</td>\n",
       "      <td>Highest average across 3 quality metrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Production Ready</td>\n",
       "      <td>Parent Document</td>\n",
       "      <td>Score: 0.540</td>\n",
       "      <td>Meets minimum thresholds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category               Retriever      Key Metric  \\\n",
       "0    Overall Winner         Parent Document    Score: 0.729   \n",
       "1     Budget Option  Contextual Compression   Cost: $0.0112   \n",
       "2    Quality Leader             Multi Query  Quality: 0.864   \n",
       "3  Production Ready         Parent Document    Score: 0.540   \n",
       "\n",
       "                                Description  \n",
       "0                 Best balanced performance  \n",
       "1                       Lowest cost per run  \n",
       "2  Highest average across 3 quality metrics  \n",
       "3                  Meets minimum thresholds  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.get_recommendations_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "818b3613-2667-4a58-a441-3a919a77fb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>retriever_chain</th>\n",
       "      <th>score</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>llm_context_precision_without_reference</th>\n",
       "      <th>faithful_rate</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>Avg_Cost_Per_Run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Parent Document</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.8583</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Multi Query</td>\n",
       "      <td>0.7278</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.0255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.0284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bm25</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4345</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Contextual Compression</td>\n",
       "      <td>0.5338</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.7773</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>0.0243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank         retriever_chain   score  context_recall  faithfulness  \\\n",
       "0     1         Parent Document  0.7290          0.8062        0.8835   \n",
       "1     2             Multi Query  0.7278          0.8445        0.8968   \n",
       "2     3                Ensemble  0.6126          0.8514        0.8915   \n",
       "3     4                    Bm25  0.6052          0.8229        0.8707   \n",
       "4     5  Contextual Compression  0.5338          0.6395        0.7827   \n",
       "5     6                   Naive  0.4459          0.7945        0.8080   \n",
       "\n",
       "   llm_context_precision_with_reference  \\\n",
       "0                                0.8583   \n",
       "1                                0.8505   \n",
       "2                                0.7677   \n",
       "3                                0.6833   \n",
       "4                                0.7333   \n",
       "5                                0.7773   \n",
       "\n",
       "   llm_context_precision_without_reference  faithful_rate  \\\n",
       "0                                   0.9333            1.0   \n",
       "1                                   0.9084            1.0   \n",
       "2                                   0.8899            1.0   \n",
       "3                                   0.9139            1.0   \n",
       "4                                   0.9833            1.0   \n",
       "5                                   0.9182            1.0   \n",
       "\n",
       "   context_entity_recall  Avg_Cost_Per_Run  \n",
       "0                 0.4451            0.0145  \n",
       "1                 0.4245            0.0255  \n",
       "2                 0.4744            0.0284  \n",
       "3                 0.4345            0.0151  \n",
       "4                 0.4495            0.0112  \n",
       "5                 0.3208            0.0243  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.get_rankings_table('weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "59dacfdc-9a64-414b-82fb-139b59c46150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retriever_chain</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>llm_context_precision_without_reference</th>\n",
       "      <th>non_llm_context_precision_with_reference</th>\n",
       "      <th>faithful_rate</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>noise_sensitivity_relevant</th>\n",
       "      <th>Avg_Cost_Per_Run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.7773</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.0243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bm25</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4345</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Contextual Compression</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.4062</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multi Query</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.0255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parent Document</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.8583</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4451</td>\n",
       "      <td>0.3173</td>\n",
       "      <td>0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          retriever_chain  context_recall  faithfulness  \\\n",
       "0                   Naive          0.7945        0.8080   \n",
       "1                    Bm25          0.8229        0.8707   \n",
       "2  Contextual Compression          0.6395        0.7827   \n",
       "3             Multi Query          0.8445        0.8968   \n",
       "4         Parent Document          0.8062        0.8835   \n",
       "5                Ensemble          0.8514        0.8915   \n",
       "\n",
       "   llm_context_precision_with_reference  \\\n",
       "0                                0.7773   \n",
       "1                                0.6833   \n",
       "2                                0.7333   \n",
       "3                                0.8505   \n",
       "4                                0.8583   \n",
       "5                                0.7677   \n",
       "\n",
       "   llm_context_precision_without_reference  \\\n",
       "0                                   0.9182   \n",
       "1                                   0.9139   \n",
       "2                                   0.9833   \n",
       "3                                   0.9084   \n",
       "4                                   0.9333   \n",
       "5                                   0.8899   \n",
       "\n",
       "   non_llm_context_precision_with_reference  faithful_rate  \\\n",
       "0                                    0.3929            1.0   \n",
       "1                                    0.4139            1.0   \n",
       "2                                    0.5083            1.0   \n",
       "3                                    0.3595            1.0   \n",
       "4                                    0.2556            1.0   \n",
       "5                                    0.3931            1.0   \n",
       "\n",
       "   context_entity_recall  noise_sensitivity_relevant  Avg_Cost_Per_Run  \n",
       "0                 0.3208                      0.2236            0.0243  \n",
       "1                 0.4345                      0.3793            0.0151  \n",
       "2                 0.4495                      0.4062            0.0112  \n",
       "3                 0.4245                      0.4545            0.0255  \n",
       "4                 0.4451                      0.3173            0.0145  \n",
       "5                 0.4744                      0.0000            0.0284  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.get_metrics_comparison_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "195d1f00-aabc-4335-877c-de790d3993b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_rank</th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>quality_first_rank</th>\n",
       "      <th>quality_first_score</th>\n",
       "      <th>balanced_rank</th>\n",
       "      <th>balanced_score</th>\n",
       "      <th>production_ready_rank</th>\n",
       "      <th>production_ready_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retriever</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bm25</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8241</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Compression</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7847</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7501</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8605</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi Query</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7278</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0665</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive</th>\n",
       "      <td>6</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7481</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7065</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parent Document</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8509</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1147</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        weighted_rank  weighted_score  quality_first_rank  \\\n",
       "retriever                                                                   \n",
       "Bm25                                4          0.6052                   2   \n",
       "Contextual Compression              5          0.5338                   4   \n",
       "Ensemble                            3          0.6126                   5   \n",
       "Multi Query                         2          0.7278                   3   \n",
       "Naive                               6          0.4459                   6   \n",
       "Parent Document                     1          0.7290                   1   \n",
       "\n",
       "                        quality_first_score  balanced_rank  balanced_score  \\\n",
       "retriever                                                                    \n",
       "Bm25                                 0.8000              4          0.8241   \n",
       "Contextual Compression               0.7847              5          0.7125   \n",
       "Ensemble                             0.7501              3          0.8605   \n",
       "Multi Query                          0.7918              2          1.0665   \n",
       "Naive                                0.7481              6          0.7065   \n",
       "Parent Document                      0.8509              1          1.1147   \n",
       "\n",
       "                        production_ready_rank  production_ready_score  \n",
       "retriever                                                              \n",
       "Bm25                                        5                  0.0000  \n",
       "Contextual Compression                      6                  0.0000  \n",
       "Ensemble                                    3                  0.2607  \n",
       "Multi Query                                 2                  0.3921  \n",
       "Naive                                       4                  0.2005  \n",
       "Parent Document                             1                  0.5397  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.get_algorithm_comparison_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
