{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_fLDElOVoop"
   },
   "source": [
    "## Task 1:  Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_env_var_is_set(env_var_name: str, human_readable_string: str = \"API Key\"):\n",
    "    api_key = os.getenv(env_var_name)\n",
    "  \n",
    "    if api_key:\n",
    "       print(f\"{env_var_name} is present\")\n",
    "    else:\n",
    "      print(f\"{env_var_name} is NOT present, paste key at the prompt:\")\n",
    "      os.environ[env_var_name] = getpass.getpass(f\"Please enter your {human_readable_string}: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wujPjGJuoPwg"
   },
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We'll want to set both our OpenAI API key and our LangSmith environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jdh8CoVWHRvs",
    "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is present\n",
      "COHERE_API_KEY is present\n",
      "TAVILY_API_KEY is present\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "check_if_env_var_is_set(\"OPENAI_API_KEY\", \"OpenAI API key\")\n",
    "check_if_env_var_is_set(\"COHERE_API_KEY\", \"Cohere API key\")\n",
    "check_if_env_var_is_set(\"TAVILY_API_KEY\", \"TAVILY API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv0glIDyHmRt",
    "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_API_KEY is present\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE7 - Certification Challenge\"\n",
    "check_if_env_var_is_set(\"LANGCHAIN_API_KEY\", \"LangSmith API Key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import graph_rag_functions\n",
    "importlib.reload(graph_rag_functions)\n",
    "from graph_rag_functions import naive_graph, contextual_compression_graph, multi_query_graph, parent_document_graph\n",
    "\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ask_naive_llm_tool(question: str):\n",
    "     \"\"\"PRIMARY TOOL: Query comprehensive federal student loan policy documents using  specialized RAG retrieval.\n",
    "      \n",
    "      USE THIS FIRST for ALL student loan questions including:\n",
    "      - Loan repayment plans and options\n",
    "      - Forgiveness programs and eligibility\n",
    "      - Payment problems and solutions\n",
    "      - Application processes and requirements\n",
    "      - Policy explanations and guidance\n",
    "      \n",
    "      This tool contains the most complete and up-to-date federal student loan information.\n",
    "    \"\"\"\n",
    "    response = naive_graph.invoke({\"question\": question})\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=response[\"response\"])],\n",
    "        \"context\": response[\"context\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91flJWtZLUrl"
   },
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0,  # Lower temperature for more consistent outputs\n",
    "    request_timeout=120,  # Longer timeout for complex operations\n",
    ")\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"action\"\n",
    "\n",
    "    return END\n",
    "\n",
    "tool_belt = [\n",
    "    ask_naive_llm_tool,\n",
    "    tavily_tool,\n",
    "    Tool(\n",
    "        name=\"StudentAid_Federal_Search\",\n",
    "        description=\"Search ONLY StudentAid.gov for official federal information: FAFSA applications, federal loan forgiveness programs, federal repayment plans, eligibility requirements\",\n",
    "        func=tavily_studentaid_search,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Mohela_Servicer_Search\",\n",
    "        description=\"Search ONLY Mohela loan servicer for account-specific help: making payments, login issues, servicer-specific repayment options, customer service contacts\",\n",
    "        func=tavily_mohela_search,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Student_Loan_Comparison_Search\",\n",
    "        description=\"Compare information across BOTH federal sources and Mohela when user needs comprehensive view or comparison of student loan options\",\n",
    "        func=tavily_student_loan_search,\n",
    "    ),\n",
    "]\n",
    "\n",
    "model = model.bind_tools(tool_belt)\n",
    "tool_node = ToolNode(tool_belt)\n",
    "\n",
    "uncompiled_graph = StateGraph(AgentState)\n",
    "\n",
    "uncompiled_graph.add_node(\"agent\", call_model)\n",
    "uncompiled_graph.add_node(\"action\", tool_node)\n",
    "\n",
    "uncompiled_graph.set_entry_point(\"agent\")\n",
    "uncompiled_graph.add_conditional_edges(\"agent\", should_continue)\n",
    "\n",
    "uncompiled_graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "naive_agent_graph = uncompiled_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tool_calls_parser_for_eval\n",
    "importlib.reload(tool_calls_parser_for_eval)\n",
    "from tool_calls_parser_for_eval import parse_logs, print_formatted_results, extract_contexts_for_eval, parse_langchain_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn4n37PQRPII",
    "outputId": "5eeedfae-089d-496e-e71f-071939fa5832",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# inputs = {\"messages\" : [HumanMessage(content=\"Who is the current captain of the Winnipeg Jets?\")]}\n",
    "# inputs = {\"messages\" : [HumanMessage(content=\"What concerns does the borrower have regarding Nelnet's communication about their student loan issuer?\")]}\n",
    "inputs = {\"messages\" : [HumanMessage(content=\"What is the issue with Aidvantage in the borrower's complaint?\")]}\n",
    "\n",
    "async for chunk in naive_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"Receiving update from node: '{node}'\")\n",
    "        if node == \"action\":\n",
    "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
    "          print_formatted_results(parse_logs(str(values[\"messages\"])))\n",
    "        print(\"\\n\")\n",
    "        print(values[\"messages\"])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {\"messages\" : [HumanMessage(content='')]}\n",
    "response = naive_agent_graph.invoke(inputs)\n",
    "\n",
    "evaluation_contexts = extract_contexts_for_eval(response[\"messages\"])\n",
    "print(f\"âœ… Extracted {len(evaluation_contexts)} contexts for evaluation\")\n",
    "parsed_data = parse_langchain_messages(response[\"messages\"])\n",
    "print_formatted_results(parsed_data)\n",
    "\n",
    "eval_sample = {\n",
    "    \"user_input\": inputs[\"messages\"][0].content,\n",
    "    \"response\": response[\"messages\"][-1].content,  # Final AI response\n",
    "    \"retrieved_contexts\": evaluation_contexts,\n",
    "    \"tools_used\": parsed_data['summary']['tools'],\n",
    "    \"num_contexts\": len(evaluation_contexts)\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸŽ¯ EVALUATION SAMPLE:\")\n",
    "print(f\"Query: {eval_sample['user_input']}\")\n",
    "print(f\"Response: {eval_sample['response'][:200]}...\")\n",
    "print(f\"Contexts: {eval_sample['num_contexts']} extracted\")\n",
    "print(f\"Tools: {eval_sample['tools_used']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Golden master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import core_functions\n",
    "importlib.reload(core_functions)\n",
    "\n",
    "from core_functions import load_and_prepare_pdf_loan_docs, generate_golden_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "student_loan_docs_dataset = load_and_prepare_pdf_loan_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "golden_master_dataset = generate_golden_master(student_loan_docs_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_master_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.cost import get_token_usage_for_openai\n",
    "\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas_metrics import extract_ragas_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation using RAGAS using the Golden master (Naive Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "for test_row in tqdm(golden_master_dataset):\n",
    "    inputs = {\"messages\" : [HumanMessage(content=test_row.eval_sample.user_input)]}\n",
    "    response = naive_agent_graph.invoke(inputs)\n",
    "\n",
    "    evaluation_contexts = extract_contexts_for_eval(response[\"messages\"])\n",
    "    eval_sample = {\n",
    "        \"user_input\": inputs[\"messages\"][0].content,\n",
    "        \"response\": response[\"messages\"][-1].content,  # Final AI response\n",
    "        \"retrieved_contexts\": evaluation_contexts,\n",
    "        \"tools_used\": parsed_data['summary']['tools'],\n",
    "        \"num_contexts\": len(evaluation_contexts)\n",
    "    }\n",
    "    test_row.eval_sample.response = eval_sample[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = eval_sample[\"retrieved_contexts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "golden_master_dataset.to_pandas().to_csv('golden-masters/naive_golden_master_dataset.csv', index=False)\n",
    "golden_master_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# golden_master_dataset.to_pandas()[10:11]['retrieved_contexts'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(golden_master_dataset.to_pandas())\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0, # Lower temperature for more consistent outputs\n",
    "        request_timeout=120   # Longer timeout for complex operations\n",
    "    )\n",
    ")\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), \n",
    "             ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    token_usage_parser=get_token_usage_for_openai,\n",
    "    run_config=custom_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "naive_raw_stats_df = pd.DataFrame([extract_ragas_metrics(result, 'gpt-4.1-mini')])\n",
    "record_metrics_from_run('Naive', naive_raw_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "def record_metrics_from_run(retriever_name, dataframe: pd.DataFrame):\n",
    "    new_dataframe = dataframe.copy()\n",
    "    columns=['context_recall', 'faithfulness', 'factual_correctness', 'answer_relevancy', 'context_entity_recall', 'noise_sensitivity_relevant']\n",
    "    metrics_filename = 'ragas-evaluation-metrics.csv'\n",
    "    dataset_df = pd.DataFrame()\n",
    "    if os.path.exists(metrics_filename):\n",
    "        dataset_df = pd.read_csv(metrics_filename)\n",
    "    new_dataframe['datetime'] = datetime.now().strftime('%Y-%m-%d %T')\n",
    "    new_dataframe['retriever'] = retriever_name\n",
    "    new_dataframe = new_dataframe[['datetime', 'retriever'] + columns]\n",
    "    dataset_df = pd.concat([dataset_df, new_dataframe])\n",
    "\n",
    "    dataset_df.to_csv(metrics_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation using RAGAS using the Golden master (Contextual Compression Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ask_contextual_compression_llm_tool(question: str):\n",
    "    \"\"\"PRIMARY TOOL: Query comprehensive federal student loan policy documents using  specialized RAG retrieval.\n",
    "      \n",
    "      USE THIS FIRST for ALL student loan questions including:\n",
    "      - Loan repayment plans and options\n",
    "      - Forgiveness programs and eligibility\n",
    "      - Payment problems and solutions\n",
    "      - Application processes and requirements\n",
    "      - Policy explanations and guidance\n",
    "      \n",
    "      This tool contains the most complete and up-to-date federal student loan information.\n",
    "    \"\"\"\n",
    "    response = contextual_compression_graph.invoke({\"question\": question})\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=response[\"response\"])],\n",
    "        \"context\": response[\"context\"]\n",
    "    }\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0,  # Lower temperature for more consistent outputs\n",
    "    request_timeout=120,  # Longer timeout for complex operations\n",
    ")\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        return \"action\"\n",
    "\n",
    "    return END\n",
    "\n",
    "tool_belt = [\n",
    "    ask_contextual_compression_llm_tool,\n",
    "    tavily_tool,\n",
    "    Tool(\n",
    "        name=\"StudentAid_Federal_Search\",\n",
    "        description=\"Search ONLY StudentAid.gov for official federal information: FAFSA applications, federal loan forgiveness programs, federal repayment plans, eligibility requirements\",\n",
    "        func=tavily_studentaid_search,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Mohela_Servicer_Search\",\n",
    "        description=\"Search ONLY Mohela loan servicer for account-specific help: making payments, login issues, servicer-specific repayment options, customer service contacts\",\n",
    "        func=tavily_mohela_search,\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Student_Loan_Comparison_Search\",\n",
    "        description=\"Compare information across BOTH federal sources and Mohela when user needs comprehensive view or comparison of student loan options\",\n",
    "        func=tavily_student_loan_search,\n",
    "    ),\n",
    "]\n",
    "\n",
    "model = model.bind_tools(tool_belt)\n",
    "tool_node = ToolNode(tool_belt)\n",
    "\n",
    "uncompiled_graph = StateGraph(AgentState)\n",
    "\n",
    "uncompiled_graph.add_node(\"agent\", call_model)\n",
    "uncompiled_graph.add_node(\"action\", tool_node)\n",
    "\n",
    "uncompiled_graph.set_entry_point(\"agent\")\n",
    "uncompiled_graph.add_conditional_edges(\"agent\", should_continue)\n",
    "\n",
    "uncompiled_graph.add_edge(\"action\", \"agent\")\n",
    "\n",
    "contextual_compression_agent_graph = uncompiled_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "cc_golden_master_dataset = copy.deepcopy(golden_master_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {\"messages\" : [HumanMessage(content=\"What concerns does the borrower have regarding Nelnet's communication about their student loan issuer?\")]}\n",
    "# response = simple_agent_graph.invoke(inputs)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "for test_row in tqdm(cc_golden_master_dataset):\n",
    "    inputs = {\"messages\" : [HumanMessage(content=test_row.eval_sample.user_input)]}\n",
    "    response = contextual_compression_agent_graph.invoke(inputs)\n",
    "\n",
    "    evaluation_contexts = extract_contexts_for_eval(response[\"messages\"])\n",
    "    eval_sample = {\n",
    "        \"user_input\": inputs[\"messages\"][0].content,\n",
    "        \"response\": response[\"messages\"][-1].content,  # Final AI response\n",
    "        \"retrieved_contexts\": evaluation_contexts,\n",
    "        \"tools_used\": parsed_data['summary']['tools'],\n",
    "        \"num_contexts\": len(evaluation_contexts)\n",
    "    }\n",
    "    test_row.eval_sample.response = eval_sample[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = eval_sample[\"retrieved_contexts\"]\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_golden_master_dataset.to_pandas().to_csv('golden-masters/cc_golden_master_dataset.csv', index=False)\n",
    "cc_golden_master_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cc_evaluation_dataset = EvaluationDataset.from_pandas(cc_golden_master_dataset.to_pandas())\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0, # Lower temperature for more consistent outputs\n",
    "        request_timeout=120   # Longer timeout for complex operations\n",
    "    )\n",
    ")\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "cc_result = evaluate(\n",
    "    dataset=cc_evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), \n",
    "             ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    token_usage_parser=get_token_usage_for_openai,\n",
    "    run_config=custom_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_raw_stats_df = pd.DataFrame([extract_ragas_metrics(cc_result, 'gpt-4.1-mini')])\n",
    "record_metrics_from_run('Contextual Compression', cc_raw_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Generation using RAGAS using the Golden master (Multi Query Retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ask_multi_query_llm_tool(question: str):\n",
    "      \"\"\"PRIMARY TOOL: Query comprehensive federal student loan policy documents using  specialized RAG retrieval.\n",
    "      \n",
    "      USE THIS FIRST for ALL student loan questions including:\n",
    "      - Loan repayment plans and options\n",
    "      - Forgiveness programs and eligibility\n",
    "      - Payment problems and solutions\n",
    "      - Application processes and requirements\n",
    "      - Policy explanations and guidance\n",
    "      \n",
    "      This tool contains the most complete and up-to-date federal student loan information.\n",
    "    \"\"\"\n",
    "    response = multi_query_graph.invoke({\"question\": question})\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=response[\"response\"])],\n",
    "        \"context\": response[\"context\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "mq_golden_master_dataset = copy.deepcopy(golden_master_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "for test_row in tqdm(mq_golden_master_dataset):\n",
    "    inputs = {\"messages\" : [HumanMessage(content=test_row.eval_sample.user_input)]}\n",
    "    response = multi_query_agent_graph.invoke(inputs)\n",
    "\n",
    "    evaluation_contexts = extract_contexts_for_eval(response[\"messages\"])\n",
    "    eval_sample = {\n",
    "        \"user_input\": inputs[\"messages\"][0].content,\n",
    "        \"response\": response[\"messages\"][-1].content,  # Final AI response\n",
    "        \"retrieved_contexts\": evaluation_contexts,\n",
    "        \"tools_used\": parsed_data['summary']['tools'],\n",
    "        \"num_contexts\": len(evaluation_contexts)\n",
    "    }\n",
    "    test_row.eval_sample.response = eval_sample[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = eval_sample[\"retrieved_contexts\"]\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mq_golden_master_dataset.to_pandas().to_csv('golden-masters/mq_golden_master_dataset.csv', index=False)\n",
    "mq_golden_master_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mq_evaluation_dataset = EvaluationDataset.from_pandas(mq_golden_master_dataset.to_pandas())\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0, # Lower temperature for more consistent outputs\n",
    "        request_timeout=120   # Longer timeout for complex operations\n",
    "    )\n",
    ")\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "mq_result = evaluate(\n",
    "    dataset=mq_evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), \n",
    "             ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    token_usage_parser=get_token_usage_for_openai,\n",
    "    run_config=custom_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mq_raw_stats_df = pd.DataFrame([extract_ragas_metrics(mq_result, 'gpt-4.1-mini')])\n",
    "record_metrics_from_run('MultiQuery', mq_raw_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_agent_graph\n",
    "importlib.reload(build_agent_graph)\n",
    "\n",
    "from build_agent_graph import get_agent_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ask_parent_document_llm_tool(question: str):\n",
    "    \"\"\"PRIMARY TOOL: Query comprehensive federal student loan policy documents using  specialized RAG retrieval.\n",
    "      \n",
    "      USE THIS FIRST for ALL student loan questions including:\n",
    "      - Loan repayment plans and options\n",
    "      - Forgiveness programs and eligibility\n",
    "      - Payment problems and solutions\n",
    "      - Application processes and requirements\n",
    "      - Policy explanations and guidance\n",
    "      \n",
    "      This tool contains the most complete and up-to-date federal student loan information.\n",
    "    \"\"\"\n",
    "    response = parent_document_graph.invoke({\"question\": question})\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=response[\"response\"])],\n",
    "        \"context\": response[\"context\"]\n",
    "    }\n",
    "\n",
    "parent_document_graph_agent = get_agent_graph([ask_parent_document_llm_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af186115dc34048955984a639eac97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.85 s, sys: 177 ms, total: 6.02 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd_golden_master_dataset = copy.deepcopy(golden_master_dataset)\n",
    "from tqdm.notebook import tqdm\n",
    "for test_row in tqdm(pd_golden_master_dataset):\n",
    "    inputs = {\"messages\" : [HumanMessage(content=test_row.eval_sample.user_input)]}\n",
    "    response = parent_document_graph_agent.invoke(inputs)\n",
    "\n",
    "    evaluation_contexts = extract_contexts_for_eval(response[\"messages\"])\n",
    "    eval_sample = {\n",
    "        \"user_input\": inputs[\"messages\"][0].content,\n",
    "        \"response\": response[\"messages\"][-1].content,  # Final AI response\n",
    "        \"retrieved_contexts\": evaluation_contexts,\n",
    "        \"tools_used\": parsed_data['summary']['tools'],\n",
    "        \"num_contexts\": len(evaluation_contexts)\n",
    "    }\n",
    "    test_row.eval_sample.response = eval_sample[\"response\"]\n",
    "    test_row.eval_sample.retrieved_contexts = eval_sample[\"retrieved_contexts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the structure of an academic calendar...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='The struc...</td>\n",
       "      <td>[non-term (includes clock-hour calendars), or ...</td>\n",
       "      <td>The structure of an academic calendarâ€”such as ...</td>\n",
       "      <td>The structure of an academic calendarâ€”whether ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medicine program clinical work, it gotta be in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Inclusion of Clinical Work in a Standard Term...</td>\n",
       "      <td>Could you please clarify your question a bit m...</td>\n",
       "      <td>If the clinical work in a medicine program mee...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wen do Title IV program disbursements need to ...</td>\n",
       "      <td>[{'messages': [HumanMessage(content=\"Title IV ...</td>\n",
       "      <td>[Non-Term Characteristics A program that measu...</td>\n",
       "      <td>Title IV program disbursements for non-term pr...</td>\n",
       "      <td>Title IV program disbursements, except for Fed...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so like if a student gettin a TEACH Grant in a...</td>\n",
       "      <td>[{'messages': [HumanMessage(content=\"Exceeding...</td>\n",
       "      <td>[both the credit or clock hours and the weeks ...</td>\n",
       "      <td>Exceeding scheduled weeks or hours in a paymen...</td>\n",
       "      <td>if a student gettin a TEACH Grant in a clock-h...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the disbursement timing for federal s...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='The disbu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement timing for federal student ai...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do the disbursement timing requirements fo...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='The disbu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement timing requirements for feder...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If a practicum or clinical experience is requi...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='Condition...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>Clinical or practicum experiences required for...</td>\n",
       "      <td>A practicum or clinical experience required fo...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do the disbursement timing requirements fo...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='The disbu...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The disbursement timing requirements for feder...</td>\n",
       "      <td>In clock-hour or non-term credit-hour programs...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acccording to Volume 8, Chapter 3, how does th...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='According...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nInclusion of Clinical Work in a St...</td>\n",
       "      <td>According to Volume 8, Chapter 3, the inclusio...</td>\n",
       "      <td>Volume 8, Chapter 3 explains that clinical wor...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how do appendix a and appendix b help schools ...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='Appendix ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>Appendix A and Appendix B provide detailed gui...</td>\n",
       "      <td>appendix a gives examples that illustrate the ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the structure of non-term and subscri...</td>\n",
       "      <td>[{'messages': [HumanMessage(content=\"The struc...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nboth the credit or clock hours and...</td>\n",
       "      <td>The structure of non-term and subscription-bas...</td>\n",
       "      <td>The structure of non-term and subscription-bas...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>According to Volume 8, Chapter 6 and Volume 8,...</td>\n",
       "      <td>[{'messages': [HumanMessage(content='The requi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nDisbursement Timing in Subscriptio...</td>\n",
       "      <td>The requirements for disbursement timing and a...</td>\n",
       "      <td>In subscription-based programs, as described i...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How does the structure of an academic calendar...   \n",
       "1   medicine program clinical work, it gotta be in...   \n",
       "2   Wen do Title IV program disbursements need to ...   \n",
       "3   so like if a student gettin a TEACH Grant in a...   \n",
       "4   How does the disbursement timing for federal s...   \n",
       "5   How do the disbursement timing requirements fo...   \n",
       "6   If a practicum or clinical experience is requi...   \n",
       "7   How do the disbursement timing requirements fo...   \n",
       "8   Acccording to Volume 8, Chapter 3, how does th...   \n",
       "9   how do appendix a and appendix b help schools ...   \n",
       "10  How does the structure of non-term and subscri...   \n",
       "11  According to Volume 8, Chapter 6 and Volume 8,...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [{'messages': [HumanMessage(content='The struc...   \n",
       "1                                                  []   \n",
       "2   [{'messages': [HumanMessage(content=\"Title IV ...   \n",
       "3   [{'messages': [HumanMessage(content=\"Exceeding...   \n",
       "4   [{'messages': [HumanMessage(content='The disbu...   \n",
       "5   [{'messages': [HumanMessage(content='The disbu...   \n",
       "6   [{'messages': [HumanMessage(content='Condition...   \n",
       "7   [{'messages': [HumanMessage(content='The disbu...   \n",
       "8   [{'messages': [HumanMessage(content='According...   \n",
       "9   [{'messages': [HumanMessage(content='Appendix ...   \n",
       "10  [{'messages': [HumanMessage(content=\"The struc...   \n",
       "11  [{'messages': [HumanMessage(content='The requi...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [non-term (includes clock-hour calendars), or ...   \n",
       "1   [Inclusion of Clinical Work in a Standard Term...   \n",
       "2   [Non-Term Characteristics A program that measu...   \n",
       "3   [both the credit or clock hours and the weeks ...   \n",
       "4   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "5   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "6   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "7   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "8   [<1-hop>\\n\\nInclusion of Clinical Work in a St...   \n",
       "9   [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "10  [<1-hop>\\n\\nboth the credit or clock hours and...   \n",
       "11  [<1-hop>\\n\\nDisbursement Timing in Subscriptio...   \n",
       "\n",
       "                                             response  \\\n",
       "0   The structure of an academic calendarâ€”such as ...   \n",
       "1   Could you please clarify your question a bit m...   \n",
       "2   Title IV program disbursements for non-term pr...   \n",
       "3   Exceeding scheduled weeks or hours in a paymen...   \n",
       "4   The disbursement timing for federal student ai...   \n",
       "5   The disbursement timing requirements for feder...   \n",
       "6   Clinical or practicum experiences required for...   \n",
       "7   The disbursement timing requirements for feder...   \n",
       "8   According to Volume 8, Chapter 3, the inclusio...   \n",
       "9   Appendix A and Appendix B provide detailed gui...   \n",
       "10  The structure of non-term and subscription-bas...   \n",
       "11  The requirements for disbursement timing and a...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The structure of an academic calendarâ€”whether ...   \n",
       "1   If the clinical work in a medicine program mee...   \n",
       "2   Title IV program disbursements, except for Fed...   \n",
       "3   if a student gettin a TEACH Grant in a clock-h...   \n",
       "4   In clock-hour or non-term credit-hour programs...   \n",
       "5   In clock-hour or non-term credit-hour programs...   \n",
       "6   A practicum or clinical experience required fo...   \n",
       "7   In clock-hour or non-term credit-hour programs...   \n",
       "8   Volume 8, Chapter 3 explains that clinical wor...   \n",
       "9   appendix a gives examples that illustrate the ...   \n",
       "10  The structure of non-term and subscription-bas...   \n",
       "11  In subscription-based programs, as described i...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_golden_master_dataset.to_pandas().to_csv('golden-masters/pd_golden_master_dataset.csv', index=False)\n",
    "pd_golden_master_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3fbecfe51e4638a65662758e18e03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[11]: ValueError(zero-size array to reduction operation maximum which has no identity)\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[47]: TimeoutError()\n",
      "Exception raised in Job[71]: TimeoutError()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.73 s, sys: 1.42 s, total: 11.1 s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd_evaluation_dataset = EvaluationDataset.from_pandas(pd_golden_master_dataset.to_pandas())\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0, # Lower temperature for more consistent outputs\n",
    "        request_timeout=120   # Longer timeout for complex operations\n",
    "    )\n",
    ")\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "pd_result = evaluate(\n",
    "    dataset=pd_evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), \n",
    "             ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    token_usage_parser=get_token_usage_for_openai,\n",
    "    run_config=custom_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_raw_stats_df = pd.DataFrame([extract_ragas_metrics(pd_result, 'gpt-4.1-mini')])\n",
    "record_metrics_from_run('Parent Document', pd_raw_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collected_df = pd.read_csv('ragas-evaluation-metrics.csv')\n",
    "collected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualize_retriever_performance\n",
    "importlib.reload(visualize_retriever_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
